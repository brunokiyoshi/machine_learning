{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "churn_modelling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1jdXpKbOMQAdExalUmnP_bUflnkCDyQMW",
      "authorship_tag": "ABX9TyNqWQe6GHOsld+LwAXUzGcZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brunokiyoshi/machine_learning/blob/master/churn_modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otSSE6uHDPTr",
        "colab_type": "text"
      },
      "source": [
        "### Churn Modelling\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyUcN5pbCwQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pUCffIvDI3h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "35ec86a9-a2fa-4da6-8ee0-ffce2d449fd5"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwxWPFxzGh0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/Churn modelling/Churn_Modelling.csv\")\n",
        "X = dataset.iloc[:, 3:-1].values\n",
        "y = dataset.iloc[:, -1].values"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duvk6yyTHXxj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "375be57f-88bf-4958-a694-6ac784be479e"
      },
      "source": [
        "X"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[619, 'France', 'Female', ..., 1, 1, 101348.88],\n",
              "       [608, 'Spain', 'Female', ..., 0, 1, 112542.58],\n",
              "       [502, 'France', 'Female', ..., 1, 0, 113931.57],\n",
              "       ...,\n",
              "       [709, 'France', 'Female', ..., 0, 1, 42085.58],\n",
              "       [772, 'Germany', 'Male', ..., 1, 0, 92888.52],\n",
              "       [792, 'France', 'Female', ..., 1, 0, 38190.78]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n51moYryIbgs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e093cbc9-6db4-4581-d68e-6d3500edaacd"
      },
      "source": [
        "y"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, ..., 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr9PCnQBIcZL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "77bf327a-bd50-40b9-b243-293c197ea0b3"
      },
      "source": [
        "# Encode categorical data (country and gender) to labels\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "# First for gender, for all rows, which is on column 3 (index = 2)\n",
        "X[:, 2] = le.fit_transform(X[:, 2])\n",
        "X\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[619, 'France', 0, ..., 1, 1, 101348.88],\n",
              "       [608, 'Spain', 0, ..., 0, 1, 112542.58],\n",
              "       [502, 'France', 0, ..., 1, 0, 113931.57],\n",
              "       ...,\n",
              "       [709, 'France', 0, ..., 0, 1, 42085.58],\n",
              "       [772, 'Germany', 1, ..., 1, 0, 92888.52],\n",
              "       [792, 'France', 0, ..., 1, 0, 38190.78]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU8AVKNAJMlv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "eb9f1ad2-30c9-4746-e871-b4579baf21a5"
      },
      "source": [
        "# Then encode geography using One Hot Encoding\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X))\n",
        "X"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0, 0.0, 0.0, ..., 1, 1, 101348.88],\n",
              "       [0.0, 0.0, 1.0, ..., 0, 1, 112542.58],\n",
              "       [1.0, 0.0, 0.0, ..., 1, 0, 113931.57],\n",
              "       ...,\n",
              "       [1.0, 0.0, 0.0, ..., 0, 1, 42085.58],\n",
              "       [0.0, 1.0, 0.0, ..., 1, 0, 92888.52],\n",
              "       [1.0, 0.0, 0.0, ..., 1, 0, 38190.78]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6krzoQPLr3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting the dataset into training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdUn8ggzMShs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "4229b16e-3117-46b5-fe48-8eeaa4133aff"
      },
      "source": [
        "# Feature scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "print(X_train[0])\n",
        "print(X_test[0])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1.01460667 -0.5698444   1.74309049  0.16958176 -1.09168714 -0.46460796\n",
            "  0.00666099 -1.21571749  0.8095029   0.64259497 -1.03227043  1.10643166]\n",
            "[-1.01460667  1.75486502 -0.57369368 -0.55204276 -1.09168714 -0.36890377\n",
            "  1.04473698  0.8793029  -0.92159124  0.64259497  0.9687384   1.61085707]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSD3VT6UMlcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initializing the ANN\n",
        "ann = tf.keras.models.Sequential()\n",
        "\n",
        "# Add input layer and first hidden layer\n",
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nSPXfG8QjRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add second hidden layer\n",
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmbiYLUvQqAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add output layer\n",
        "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid')) # only one output"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpv7rRFwRTus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compiling\n",
        "# adam = stochastic gradient descent\n",
        "# binary_crossentropy - always used in binary classification\n",
        "ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-ENlCXsSr5i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3274f005-c4fc-4c06-e992-5e0af17fbd5a"
      },
      "source": [
        "# Training\n",
        "ann.fit(X_train, y_train, batch_size=32, epochs=100)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "250/250 [==============================] - 0s 770us/step - loss: 0.5040 - accuracy: 0.7958\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 0s 775us/step - loss: 0.4411 - accuracy: 0.7961\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 0s 842us/step - loss: 0.4214 - accuracy: 0.8124\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 0s 771us/step - loss: 0.4123 - accuracy: 0.8166\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 0s 781us/step - loss: 0.4070 - accuracy: 0.8191\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 0s 846us/step - loss: 0.4031 - accuracy: 0.8205\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 0s 806us/step - loss: 0.3998 - accuracy: 0.8225\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 0s 776us/step - loss: 0.3967 - accuracy: 0.8226\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 0s 801us/step - loss: 0.3937 - accuracy: 0.8240\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 0s 769us/step - loss: 0.3911 - accuracy: 0.8263\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 0s 865us/step - loss: 0.3879 - accuracy: 0.8271\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 0s 801us/step - loss: 0.3839 - accuracy: 0.8274\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 0s 831us/step - loss: 0.3789 - accuracy: 0.8339\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 0s 765us/step - loss: 0.3742 - accuracy: 0.8419\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 0s 795us/step - loss: 0.3706 - accuracy: 0.8454\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 0s 779us/step - loss: 0.3672 - accuracy: 0.8464\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 0s 792us/step - loss: 0.3646 - accuracy: 0.8506\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 0s 836us/step - loss: 0.3627 - accuracy: 0.8533\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 0s 786us/step - loss: 0.3604 - accuracy: 0.8562\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 0s 785us/step - loss: 0.3586 - accuracy: 0.8544\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 0s 786us/step - loss: 0.3566 - accuracy: 0.8549\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 0s 775us/step - loss: 0.3557 - accuracy: 0.8560\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 0s 796us/step - loss: 0.3542 - accuracy: 0.8554\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 0s 795us/step - loss: 0.3525 - accuracy: 0.8554\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 0s 775us/step - loss: 0.3512 - accuracy: 0.8565\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 0s 784us/step - loss: 0.3501 - accuracy: 0.8576\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 0s 804us/step - loss: 0.3488 - accuracy: 0.8564\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 0s 815us/step - loss: 0.3472 - accuracy: 0.8597\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 0s 791us/step - loss: 0.3476 - accuracy: 0.8590\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 0s 758us/step - loss: 0.3455 - accuracy: 0.8600\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 0s 800us/step - loss: 0.3449 - accuracy: 0.8606\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 0s 811us/step - loss: 0.3439 - accuracy: 0.8611\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 0s 794us/step - loss: 0.3429 - accuracy: 0.8604\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 0s 781us/step - loss: 0.3424 - accuracy: 0.8619\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 0s 776us/step - loss: 0.3410 - accuracy: 0.8620\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 0s 779us/step - loss: 0.3407 - accuracy: 0.8637\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 0s 996us/step - loss: 0.3401 - accuracy: 0.8640\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 0s 894us/step - loss: 0.3391 - accuracy: 0.8646\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 0s 776us/step - loss: 0.3388 - accuracy: 0.8631\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 0s 796us/step - loss: 0.3382 - accuracy: 0.8651\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 0s 868us/step - loss: 0.3379 - accuracy: 0.8619\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 0s 842us/step - loss: 0.3373 - accuracy: 0.8640\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 0s 794us/step - loss: 0.3371 - accuracy: 0.8635\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 0s 787us/step - loss: 0.3369 - accuracy: 0.8624\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 0s 811us/step - loss: 0.3359 - accuracy: 0.8643\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 0s 774us/step - loss: 0.3360 - accuracy: 0.8640\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 0s 815us/step - loss: 0.3355 - accuracy: 0.8658\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 0s 826us/step - loss: 0.3353 - accuracy: 0.8656\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 0s 788us/step - loss: 0.3349 - accuracy: 0.8635\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 0s 770us/step - loss: 0.3348 - accuracy: 0.8652\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 0s 794us/step - loss: 0.3338 - accuracy: 0.8650\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 0s 821us/step - loss: 0.3344 - accuracy: 0.8649\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 0s 786us/step - loss: 0.3344 - accuracy: 0.8654\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 0s 792us/step - loss: 0.3339 - accuracy: 0.8665\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 0s 818us/step - loss: 0.3331 - accuracy: 0.8639\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 0s 792us/step - loss: 0.3329 - accuracy: 0.8665\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 0s 800us/step - loss: 0.3331 - accuracy: 0.8650\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 0s 771us/step - loss: 0.3325 - accuracy: 0.8660\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 0s 782us/step - loss: 0.3326 - accuracy: 0.8662\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 0s 786us/step - loss: 0.3325 - accuracy: 0.8645\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 0s 763us/step - loss: 0.3327 - accuracy: 0.8666\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 0s 832us/step - loss: 0.3322 - accuracy: 0.8641\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 0s 751us/step - loss: 0.3318 - accuracy: 0.8651\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 0s 793us/step - loss: 0.3321 - accuracy: 0.8665\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 0s 767us/step - loss: 0.3321 - accuracy: 0.8670\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 0s 788us/step - loss: 0.3316 - accuracy: 0.8649\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 0s 832us/step - loss: 0.3321 - accuracy: 0.8664\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 0s 782us/step - loss: 0.3313 - accuracy: 0.8658\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 0s 765us/step - loss: 0.3313 - accuracy: 0.8655\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 0s 762us/step - loss: 0.3320 - accuracy: 0.8654\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 0s 835us/step - loss: 0.3309 - accuracy: 0.8660\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 0s 801us/step - loss: 0.3313 - accuracy: 0.8661\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 0s 780us/step - loss: 0.3305 - accuracy: 0.8656\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 0s 785us/step - loss: 0.3309 - accuracy: 0.8627\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 0s 832us/step - loss: 0.3308 - accuracy: 0.8665\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 0s 757us/step - loss: 0.3307 - accuracy: 0.8664\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 0s 841us/step - loss: 0.3304 - accuracy: 0.8659\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 0s 749us/step - loss: 0.3303 - accuracy: 0.8656\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 0s 777us/step - loss: 0.3310 - accuracy: 0.8655\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 0s 784us/step - loss: 0.3306 - accuracy: 0.8658\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 0s 797us/step - loss: 0.3308 - accuracy: 0.8650\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 0s 793us/step - loss: 0.3306 - accuracy: 0.8646\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 0s 793us/step - loss: 0.3309 - accuracy: 0.8656\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 0s 858us/step - loss: 0.3305 - accuracy: 0.8661\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 0s 797us/step - loss: 0.3307 - accuracy: 0.8676\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 0s 779us/step - loss: 0.3306 - accuracy: 0.8648\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 0s 794us/step - loss: 0.3301 - accuracy: 0.8662\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 0s 765us/step - loss: 0.3303 - accuracy: 0.8645\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 0s 792us/step - loss: 0.3299 - accuracy: 0.8669\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 0s 750us/step - loss: 0.3302 - accuracy: 0.8650\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 0s 765us/step - loss: 0.3301 - accuracy: 0.8658\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 0s 825us/step - loss: 0.3295 - accuracy: 0.8664\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 0s 775us/step - loss: 0.3307 - accuracy: 0.8651\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 0s 786us/step - loss: 0.3297 - accuracy: 0.8658\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 0s 787us/step - loss: 0.3304 - accuracy: 0.8627\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 0s 785us/step - loss: 0.3300 - accuracy: 0.8654\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 0s 811us/step - loss: 0.3306 - accuracy: 0.8666\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 0s 786us/step - loss: 0.3296 - accuracy: 0.8634\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 0s 792us/step - loss: 0.3301 - accuracy: 0.8673\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 0s 858us/step - loss: 0.3294 - accuracy: 0.8669\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f21d3f27d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSmz3_KmTNU3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6561dc90-5f63-46a3-8780-286dc233c982"
      },
      "source": [
        "'''\n",
        "Geography: French ([1, 0, 0])\n",
        "Credit score: 600\n",
        "Gender: Male (1)\n",
        "Age: 40\n",
        "Tenure: 3 years\n",
        "Balance 60K\n",
        "Products: 2\n",
        "Credit card: yes\n",
        "Active member: yes\n",
        "Salary: 50K\n",
        "^ is this costumer likely to leave the bank?\n",
        "'''\n",
        "# Any input of the predict method should be a 2D array\n",
        "customer_data = [1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]\n",
        "customers_to_evaluate = [customer_data]\n",
        "customers_to_evaluate_scaled = sc.transform(customers_to_evaluate)\n",
        "print(ann.predict(customers_to_evaluate_scaled) > 0.5)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[False]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHTfXGIkVcp8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "9e3c34ab-716d-481d-f84d-d0398dd70a3c"
      },
      "source": [
        "predictions = ann.predict(X_test)\n",
        "predictions = (predictions > 0.5)\n",
        "# print(predictions)\n",
        "# print(y_test)\n",
        "print(np.concatenate((np.reshape(predictions, (len(predictions), 1)), np.reshape(y_test, (len(y_test),1))), 1))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0]\n",
            " [0 1]\n",
            " [0 0]\n",
            " ...\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00GcexohY92H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "7de2e583-59ac-477a-9099-ab79ec24ff58"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, predictions)\n",
        "print(cm)\n",
        "accuracy_score(y_test, predictions)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1490  105]\n",
            " [ 173  232]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.861"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxFWolxuZ1-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}